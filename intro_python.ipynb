{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print('hello world')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/2d/5e/9213ea10ac473e2437dc2cb17323ddc0999997e2713d6a0b683b10773994/pandas-2.1.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading pandas-2.1.1-cp311-cp311-win_amd64.whl.metadata (18 kB)\n",
      "Collecting numpy>=1.23.2 (from pandas)\n",
      "  Obtaining dependency information for numpy>=1.23.2 from https://files.pythonhosted.org/packages/93/fd/3f826c6d15d3bdcf65b8031e4835c52b7d9c45add25efa2314b53850e1a2/numpy-1.26.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached numpy-1.26.0-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\leaco\\onedrive\\documents\\github\\intro_cloud_lea\\.venv\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Obtaining dependency information for pytz>=2020.1 from https://files.pythonhosted.org/packages/32/4d/aaf7eff5deb402fd9a24a1449a8119f00d74ae9c2efa79f8ef9994261fc2/pytz-2023.3.post1-py2.py3-none-any.whl.metadata\n",
      "  Downloading pytz-2023.3.post1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas)\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "     ---------------------------------------- 0.0/341.8 kB ? eta -:--:--\n",
      "     --- ------------------------------------ 30.7/341.8 kB ? eta -:--:--\n",
      "     --- ------------------------------------ 30.7/341.8 kB ? eta -:--:--\n",
      "     ------- ----------------------------- 71.7/341.8 kB 777.7 kB/s eta 0:00:01\n",
      "     --------- --------------------------- 92.2/341.8 kB 744.7 kB/s eta 0:00:01\n",
      "     ------------ ----------------------- 122.9/341.8 kB 654.9 kB/s eta 0:00:01\n",
      "     --------------- -------------------- 143.4/341.8 kB 652.5 kB/s eta 0:00:01\n",
      "     -------------------- --------------- 194.6/341.8 kB 692.9 kB/s eta 0:00:01\n",
      "     ----------------------- ------------ 225.3/341.8 kB 687.0 kB/s eta 0:00:01\n",
      "     ----------------------------- ------ 276.5/341.8 kB 710.0 kB/s eta 0:00:01\n",
      "     -------------------------------- --- 307.2/341.8 kB 729.6 kB/s eta 0:00:01\n",
      "     -------------------------------- --- 307.2/341.8 kB 729.6 kB/s eta 0:00:01\n",
      "     ------------------------------------ 341.8/341.8 kB 683.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\leaco\\onedrive\\documents\\github\\intro_cloud_lea\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.1.1-cp311-cp311-win_amd64.whl (10.6 MB)\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/10.6 MB 1.4 MB/s eta 0:00:08\n",
      "   ---------------------------------------- 0.1/10.6 MB 787.7 kB/s eta 0:00:14\n",
      "    --------------------------------------- 0.2/10.6 MB 1.5 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.4/10.6 MB 2.0 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.9/10.6 MB 4.2 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 1.0/10.6 MB 3.9 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 1.9/10.6 MB 6.1 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.9/10.6 MB 6.1 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.6/10.6 MB 6.4 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.9/10.6 MB 7.0 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.9/10.6 MB 7.0 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.9/10.6 MB 7.0 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.9/10.6 MB 7.0 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.9/10.6 MB 7.0 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.9/10.6 MB 7.0 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.9/10.6 MB 7.0 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.9/10.6 MB 7.0 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.9/10.6 MB 7.0 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.9/10.6 MB 7.0 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.3/10.6 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 3.3/10.6 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 3.4/10.6 MB 3.3 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.5/10.6 MB 3.3 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.5/10.6 MB 3.2 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.6/10.6 MB 3.2 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 3.7/10.6 MB 3.1 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 3.9/10.6 MB 3.2 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 3.9/10.6 MB 3.2 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 4.1/10.6 MB 3.1 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 4.2/10.6 MB 3.1 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 4.3/10.6 MB 3.0 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 4.4/10.6 MB 3.0 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 4.4/10.6 MB 3.0 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 4.6/10.6 MB 3.0 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 4.6/10.6 MB 3.0 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 4.8/10.6 MB 2.9 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 4.8/10.6 MB 2.9 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 4.8/10.6 MB 2.8 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 4.8/10.6 MB 2.8 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 4.8/10.6 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 5.0/10.6 MB 2.7 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 5.1/10.6 MB 2.6 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 5.2/10.6 MB 2.6 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 5.4/10.6 MB 2.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 5.9/10.6 MB 2.9 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 5.9/10.6 MB 2.9 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.3/10.6 MB 2.9 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 6.4/10.6 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 6.4/10.6 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 6.4/10.6 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 6.4/10.6 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 6.9/10.6 MB 2.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 6.9/10.6 MB 2.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 8.3/10.6 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.5/10.6 MB 3.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.7/10.6 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.2/10.6 MB 3.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.3/10.6 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.8/10.6 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.9/10.6 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.4/10.6 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.4/10.6 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.6/10.6 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.6/10.6 MB 3.8 MB/s eta 0:00:00\n",
      "Using cached numpy-1.26.0-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "Downloading pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
      "   ---------------------------------------- 0.0/502.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 502.5/502.5 kB 15.9 MB/s eta 0:00:00\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-1.26.0 pandas-2.1.1 pytz-2023.3.post1 tzdata-2023.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The variable has the value: hello world\n"
     ]
    }
   ],
   "source": [
    "x='hello world'\n",
    "print(\"The variable has the value:\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "x=3\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bool'>\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "t_boolean = True\n",
    "print(type(t_boolean)) #type of the bolean\n",
    "compute_boolean = 1 + 1 == 1 #we ask if it's true or false\n",
    "print(compute_boolean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "44\n"
     ]
    }
   ],
   "source": [
    "t_integer = 12\n",
    "print(type(t_integer))\n",
    "compute_integer =40 + 6 - 2\n",
    "print(compute_integer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'float'>\n",
      "17.1\n"
     ]
    }
   ],
   "source": [
    "t_float = 12.58 \n",
    "print(type(t_float))\n",
    "compute_float = 1.5 + 10.7 + 4.9 # /!\\ use . not ,\n",
    "print(compute_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "4004 Error\n"
     ]
    }
   ],
   "source": [
    "t_string = 'Hello' #string is text\n",
    "print(type(t_string))\n",
    "compute_string= '400' + '4' + ' Error'\n",
    "print(compute_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_quote = 'Hello'\n",
    "doulbe_quote = \"Hello\"\n",
    "multilign_string = '''This is\n",
    "a multiline string\n",
    "If you need to store\n",
    "long arrays of characters.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chapter', 1, 'This', 'Is', 'a', 'list', 'of', 'strings', '.']\n"
     ]
    }
   ],
   "source": [
    "t_list=['Chapter', 1, \"This\", \"Is\", 'a', 'list', 'of', 'strings', \".\"]\n",
    "print(t_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Peugeot': 306, 'Mercedes-Benz': 'C220', 'Audi': 'A4'}\n"
     ]
    }
   ],
   "source": [
    "t_dictionary ={'Peugeot': 306, \"Mercedes-Benz\": \"C220\", \"Audi\": \"A4\"} #you assign value to another one \n",
    "print(t_dictionary) #dictionnary allow to conserv a lot of data in lot of list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       City  Population\n",
      "0     Paris     2161000\n",
      "1      Lyon      513275\n",
      "2  Bordeaux      249712\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = {\n",
    "    \"City\": ['Paris', 'Lyon', 'Bordeaux'],\n",
    "    \"Population\": [2161000, 513275, 249712]\n",
    "}\n",
    "t_dataframe = pd.DataFrame(data) \n",
    "print(t_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infinite\n",
      "Platinium\n",
      "Gold\n",
      "Classic\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "cartes = ['Infinite', 'Platinium', 'Gold', 'Classic']\n",
    "for carte in cartes:\n",
    "    print(carte)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "montant = 0\n",
    "plafond = 100\n",
    "while montant < plafond:\n",
    "    print(montant) \n",
    "    montant += 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compte créditeur\n"
     ]
    }
   ],
   "source": [
    "montant_compte = 50\n",
    "if montant_compte < -500:\n",
    "    print(\"Compte en contentieux\")\n",
    "elif montant_compte < 0:\n",
    "    print(\"Compte débiteur\")\n",
    "else: \n",
    "    print(\"Compte créditeur\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_account_statut (montant_compte): #function \n",
    "    if montant_compte < -500: \n",
    "        statut='Compte en contentieux'\n",
    "    elif montant_compte < 0:\n",
    "        statut=\"Compte débiteur\"\n",
    "    else:\n",
    "        statut='Compte créditeur'\n",
    "    return statut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Compte débiteur'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "montant = -50\n",
    "check_account_statut(montant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq_top_companies = [\n",
    "    {\n",
    "        \"Ticker\": \"AAPL\",\n",
    "        \"Company\": \"Apple Inc.\",\n",
    "        \"Industry\": \"Technology\",\n",
    "        \"Market Cap\": \"Trillion Dollars\",\n",
    "        \"Share_Price\": 150.00,\n",
    "        \"Description\": \"Share price for Apple Inc. in September 2021\"\n",
    "    },\n",
    "    {\n",
    "        \"Ticker\": \"MSFT\",\n",
    "        \"Company\": \"Microsoft Corporation\",\n",
    "        \"Industry\": \"Technology\",\n",
    "        \"Market Cap\": \"Trillion Dollars\",\n",
    "        \"Share_Price\": 300.00,\n",
    "        \"Description\": \"Share price for Microsoft Corporation in September 2021\"\n",
    "    },\n",
    "    {\n",
    "        \"Ticker\": \"AMZN\",\n",
    "        \"Company\": \"Amazon.com Inc.\",\n",
    "        \"Industry\": \"E-commerce\",\n",
    "        \"Market Cap\": \"Trillion Dollars\",\n",
    "        \"Share_Price\": 3400.00,\n",
    "        \"Description\": \"Share price for Amazon.com Inc. in September 2021\"\n",
    "    },\n",
    "    {\n",
    "        \"Ticker\": \"GOOGL\",\n",
    "        \"Company\": \"Alphabet Inc. (Google)\",\n",
    "        \"Industry\": \"Technology\",\n",
    "        \"Market Cap\": \"Trillion Dollars\",\n",
    "        \"Share_Price\": 2700.00,\n",
    "        \"Description\": \"Share price for Alphabet Inc. in September 2021\"\n",
    "    },\n",
    "    {\n",
    "        \"Ticker\": \"FB\",\n",
    "        \"Company\": \"Meta Platforms, Inc. (Facebook)\",\n",
    "        \"Industry\": \"Social Media\",\n",
    "        \"Market Cap\": \"Trillion Dollars\",\n",
    "        \"Share_Price\": 330.00,\n",
    "        \"Description\": \"Share price for Meta Platforms, Inc. in September 2021\"\n",
    "    }\n",
    "]\n",
    "# Load dict to DataFrame\n",
    "df_nasdaq=pd.DataFrame(nasdaq_top_companies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\leaco\\OneDrive\\Documents\\GitHub\\intro_cloud_lea\\seance_1.ipynb Cell 22\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/leaco/OneDrive/Documents/GitHub/intro_cloud_lea/seance_1.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m cac40_data \u001b[39m=\u001b[39m [\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/leaco/OneDrive/Documents/GitHub/intro_cloud_lea/seance_1.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     {\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/leaco/OneDrive/Documents/GitHub/intro_cloud_lea/seance_1.ipynb#X30sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTicker\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mAC\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/leaco/OneDrive/Documents/GitHub/intro_cloud_lea/seance_1.ipynb#X30sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     },\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/leaco/OneDrive/Documents/GitHub/intro_cloud_lea/seance_1.ipynb#X30sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m ]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/leaco/OneDrive/Documents/GitHub/intro_cloud_lea/seance_1.ipynb#X30sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Load dict to DataFrame\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/leaco/OneDrive/Documents/GitHub/intro_cloud_lea/seance_1.ipynb#X30sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m cac40_data\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mDataFrame(cac40_data)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "cac40_data = [\n",
    "    {\n",
    "        \"Ticker\": \"AC\",\n",
    "        \"Company\": \"Accor\",\n",
    "        \"Share_Price\": 35.60\n",
    "    },\n",
    "    {\n",
    "        \"Ticker\": \"AI\",\n",
    "        \"Company\": \"Air Liquide\",\n",
    "        \"Share_Price\": 147.80\n",
    "    },\n",
    "    {\n",
    "        \"Ticker\": \"MT\",\n",
    "        \"Company\": \"ArcelorMittal\",\n",
    "        \"Share_Price\": 28.90\n",
    "    },\n",
    "    {\n",
    "        \"Ticker\": \"BNP\",\n",
    "        \"Company\": \"BNP Paribas\",\n",
    "        \"Share_Price\": 53.20\n",
    "    },\n",
    "    {\n",
    "        \"Ticker\": \"CAP\",\n",
    "        \"Company\": \"Capgemini\",\n",
    "        \"Share_Price\": 140.45\n",
    "    },\n",
    "]\n",
    "# Load dict to DataFrame\n",
    "cac40_data=pd.DataFrame(cac40_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Company</th>\n",
       "      <th>Share_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AC</td>\n",
       "      <td>Accor</td>\n",
       "      <td>35.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AI</td>\n",
       "      <td>Air Liquide</td>\n",
       "      <td>147.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MT</td>\n",
       "      <td>ArcelorMittal</td>\n",
       "      <td>28.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BNP</td>\n",
       "      <td>BNP Paribas</td>\n",
       "      <td>53.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CAP</td>\n",
       "      <td>Capgemini</td>\n",
       "      <td>140.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker        Company  Share_Price\n",
       "0     AC          Accor        35.60\n",
       "1     AI    Air Liquide       147.80\n",
       "2     MT  ArcelorMittal        28.90\n",
       "3    BNP    BNP Paribas        53.20\n",
       "4    CAP      Capgemini       140.45"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nasdaq_top_companies\n",
    "cac40_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Impossible de créer un fichier déjà existant: './MARKET_DATA/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1.ipynb Cell 24\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X41sdW50aXRsZWQ%3D?line=0'>1</a>\u001b[0m os\u001b[39m.\u001b[39;49mmkdir(\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./MARKET_DATA/\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39m#we're going to create one document by company \u001b[39;00m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Impossible de créer un fichier déjà existant: './MARKET_DATA/'"
     ]
    }
   ],
   "source": [
    "os.mkdir(r'./MARKET_DATA/') #we're going to create one document by company, you can see that the foldr has been created on \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateCsvFile(df, PrefixName: str):\n",
    "    '''\n",
    "    The function CreateCsvFile enables to create multiple csv files by tickers \n",
    "    from a dataframe and a prefix as the filename.\n",
    "    '''\n",
    "    for line, ticker in zip(df['Ticker'], df['Ticker']):\n",
    "        pathName = r'./MARKET_DATA/'+ str(PrefixName) +str(ticker)+'.csv'\n",
    "        df[df['Ticker']==line].to_csv(pathName, index=False)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "CreateCsvFile(df_nasdaq, 'NASDAQ_')\n",
    "CreateCsvFile(cac40_data, 'CAC40_')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the folder to parse\n",
    "pathFolder = r'.\\MARKET_DATA'\n",
    "# Parse the folder\n",
    "walkFolder = [path[0] for path in os.walk (pathFolder)]\n",
    "# Initialize list\n",
    "listOfFile = []\n",
    "# Loop on the folder\n",
    "for folder in walkFolder:\n",
    "    # Assign folder path\n",
    "    folderName = os.path.basename(folder)\n",
    "    # Assign folder path joined to a file type searched\n",
    "    files = os.path.join(folder, 'NASDAQ_*.csv') #we only want nasdaq file \n",
    "    # Store the file path matching the file type searched\n",
    "    listOfFile = glob.glob(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.\\\\MARKET_DATA\\\\NASDAQ_AAPL.csv',\n",
       " '.\\\\MARKET_DATA\\\\NASDAQ_AMZN.csv',\n",
       " '.\\\\MARKET_DATA\\\\NASDAQ_FB.csv',\n",
       " '.\\\\MARKET_DATA\\\\NASDAQ_GOOGL.csv',\n",
       " '.\\\\MARKET_DATA\\\\NASDAQ_MSFT.csv']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listOfFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list, we want to concatenate all the file in only one \n",
    "full_list = []\n",
    "# Loop on all files\n",
    "for file in listOfFile:\n",
    "    # Import data to a Dataframe\n",
    "    full_file = pd.read_csv(file, dtype = str).reset_index(drop = True)\n",
    "    # Assign the file path to the file_name columns\n",
    "    full_file['file_name']=os.path.basename(file)\n",
    "    # Append the DataFrame to the list initialized\n",
    "    full_list.append(full_file)\n",
    "# Merge the list of DataFrames to a single DataFrame\n",
    "fileConcat = pd.concat(full_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Company</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Market Cap</th>\n",
       "      <th>Share_Price</th>\n",
       "      <th>Description</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Trillion Dollars</td>\n",
       "      <td>150.0</td>\n",
       "      <td>Share price for Apple Inc. in September 2021</td>\n",
       "      <td>NASDAQ_AAPL.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>Amazon.com Inc.</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Trillion Dollars</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>Share price for Amazon.com Inc. in September 2021</td>\n",
       "      <td>NASDAQ_AMZN.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FB</td>\n",
       "      <td>Meta Platforms, Inc. (Facebook)</td>\n",
       "      <td>Social Media</td>\n",
       "      <td>Trillion Dollars</td>\n",
       "      <td>330.0</td>\n",
       "      <td>Share price for Meta Platforms, Inc. in Septem...</td>\n",
       "      <td>NASDAQ_FB.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOOGL</td>\n",
       "      <td>Alphabet Inc. (Google)</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Trillion Dollars</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>Share price for Alphabet Inc. in September 2021</td>\n",
       "      <td>NASDAQ_GOOGL.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>Microsoft Corporation</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Trillion Dollars</td>\n",
       "      <td>300.0</td>\n",
       "      <td>Share price for Microsoft Corporation in Septe...</td>\n",
       "      <td>NASDAQ_MSFT.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker                          Company      Industry        Market Cap  \\\n",
       "0   AAPL                       Apple Inc.    Technology  Trillion Dollars   \n",
       "0   AMZN                  Amazon.com Inc.    E-commerce  Trillion Dollars   \n",
       "0     FB  Meta Platforms, Inc. (Facebook)  Social Media  Trillion Dollars   \n",
       "0  GOOGL           Alphabet Inc. (Google)    Technology  Trillion Dollars   \n",
       "0   MSFT            Microsoft Corporation    Technology  Trillion Dollars   \n",
       "\n",
       "  Share_Price                                        Description  \\\n",
       "0       150.0       Share price for Apple Inc. in September 2021   \n",
       "0      3400.0  Share price for Amazon.com Inc. in September 2021   \n",
       "0       330.0  Share price for Meta Platforms, Inc. in Septem...   \n",
       "0      2700.0    Share price for Alphabet Inc. in September 2021   \n",
       "0       300.0  Share price for Microsoft Corporation in Septe...   \n",
       "\n",
       "          file_name  \n",
       "0   NASDAQ_AAPL.csv  \n",
       "0   NASDAQ_AMZN.csv  \n",
       "0     NASDAQ_FB.csv  \n",
       "0  NASDAQ_GOOGL.csv  \n",
       "0   NASDAQ_MSFT.csv  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileConcat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
